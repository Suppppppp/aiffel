{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mnist classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist_data = load_digits()\n",
    "\n",
    "feature = mnist_data.data\n",
    "label = mnist_data.target\n",
    "\n",
    "print(mnist_data.target_names)\n",
    "\n",
    "plt.imshow(feature[0].reshape(8,8), cmap=plt.cm.binary)  # digit에 담긴정보를 시각화  # cmap=plt.cm.binary을 인자로 넣어주므로써 binary정보 시각화\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(feature,\n",
    "                                                 label,\n",
    "                                                 test_size = 0.2 ,\n",
    "                                                 random_state = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1. using Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99        38\n",
      "           1       0.80      0.78      0.79        36\n",
      "           2       0.79      0.84      0.82        32\n",
      "           3       0.92      0.88      0.90        56\n",
      "           4       0.79      0.84      0.81        31\n",
      "           5       0.92      0.94      0.93        36\n",
      "           6       0.94      0.94      0.94        34\n",
      "           7       0.97      0.85      0.91        34\n",
      "           8       0.81      0.78      0.79        27\n",
      "           9       0.80      0.92      0.86        36\n",
      "\n",
      "    accuracy                           0.88       360\n",
      "   macro avg       0.87      0.87      0.87       360\n",
      "weighted avg       0.88      0.88      0.88       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "prediction_value = model.predict(x_test)\n",
    "\n",
    "\n",
    "# checking Evaluate\n",
    "print(classification_report(y_test,prediction_value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 2. using Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        38\n",
      "           1       0.97      1.00      0.99        36\n",
      "           2       0.97      1.00      0.98        32\n",
      "           3       1.00      0.98      0.99        56\n",
      "           4       1.00      0.97      0.98        31\n",
      "           5       0.97      0.97      0.97        36\n",
      "           6       1.00      1.00      1.00        34\n",
      "           7       1.00      1.00      1.00        34\n",
      "           8       1.00      0.93      0.96        27\n",
      "           9       0.95      1.00      0.97        36\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.98      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "predict_value = model.predict(x_test)\n",
    "\n",
    "# checking evaluate\n",
    "print(classification_report(y_test,predict_value))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. using SVM (Support vector machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        38\n",
      "           1       1.00      1.00      1.00        36\n",
      "           2       1.00      1.00      1.00        32\n",
      "           3       1.00      1.00      1.00        56\n",
      "           4       1.00      0.97      0.98        31\n",
      "           5       1.00      0.97      0.99        36\n",
      "           6       1.00      1.00      1.00        34\n",
      "           7       1.00      1.00      1.00        34\n",
      "           8       1.00      1.00      1.00        27\n",
      "           9       0.95      1.00      0.97        36\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "\n",
    "model = svm.SVC()\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "predict_value = model.predict(x_test)\n",
    "\n",
    "# checking evaluate\n",
    "print(classification_report(y_test,predict_value))\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 4. using SGD Classifier (Stochastic Gradient Descent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99        38\n",
      "           1       0.94      0.94      0.94        36\n",
      "           2       1.00      1.00      1.00        32\n",
      "           3       0.98      0.98      0.98        56\n",
      "           4       1.00      0.97      0.98        31\n",
      "           5       0.97      0.94      0.96        36\n",
      "           6       1.00      1.00      1.00        34\n",
      "           7       1.00      1.00      1.00        34\n",
      "           8       0.90      0.96      0.93        27\n",
      "           9       0.95      0.97      0.96        36\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.98      0.97      0.98       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "\n",
    "model = SGDClassifier()\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "predict_value = model.predict(x_test)\n",
    "\n",
    "# checking evaluate\n",
    "print(classification_report(y_test,predict_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 5. using Logistic REgression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97        38\n",
      "           1       0.95      0.97      0.96        36\n",
      "           2       1.00      0.97      0.98        32\n",
      "           3       1.00      0.98      0.99        56\n",
      "           4       1.00      0.97      0.98        31\n",
      "           5       0.94      0.92      0.93        36\n",
      "           6       1.00      1.00      1.00        34\n",
      "           7       1.00      0.97      0.99        34\n",
      "           8       0.96      1.00      0.98        27\n",
      "           9       0.88      1.00      0.94        36\n",
      "\n",
      "    accuracy                           0.97       360\n",
      "   macro avg       0.97      0.97      0.97       360\n",
      "weighted avg       0.97      0.97      0.97       360\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "predict_value = model.predict(x_test)\n",
    "\n",
    "# checking evaluate\n",
    "print(classification_report(y_test,predict_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### select one of the confusion matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 경우 confusion matrix의 지표 중 하나를 택한다면 Accuracy을 선택할 것이다.  \n",
    "이유)\n",
    "1. 데이터가 balnced data 이다\n",
    "2. 전체 데이터에서 맞춘 것 뿐만 아니라 못맞춘 것도 같이 고려해 줄 수 있다\n",
    "3. 2번이 가능한 이유는 1번의 이유로 data자체가 balnced data이기 때문이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 label의 분배\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    178\n",
       "1    182\n",
       "2    177\n",
       "3    183\n",
       "4    181\n",
       "5    182\n",
       "6    181\n",
       "7    179\n",
       "8    174\n",
       "9    180\n",
       "dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'데이터 label의 분배')\n",
    "pd.Series(label).value_counts().sort_index()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
