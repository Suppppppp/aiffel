{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 가위바위보 게임 인공지능 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://teachablemachine.withgoogle.com/ \n",
    "Get Started -> Image Project 를 통해 이미지 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 데이터 불러오기 & Resize하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "# PIL 라이브러리가 설치되어 있지 않다면 \n",
    "# 아래의 코드로 설치\n",
    "# !pip install pillow   \n",
    "\n",
    "from PIL import Image\n",
    "import os, glob\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 가위사진  Resize ( 나머지들도 동일한 방식으로 resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/scissor\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/scissor_*.jpg\")  # /scissor_뒤에 오는 모든 숫자를 *로 표현\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### dataset 사진 파일이 jpg가 아닌 png의 경우 jpg로 변환하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel/aiffel/rock_scissor_paper/scissor\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/scissor_*.png\")  # /scissor_뒤에 *은\n",
    "앞에  멀\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    old_img=old_img.convert('RGB')\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  [ 폴더의 이미지들 모으려고하는데 이름들이 모두 겹칠 때 사용 ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os \n",
    "\n",
    "\n",
    "file_path = '/home/aiffel/aiffel/2ndWeek_0727_0731/rock_scissor_paper/dataset/'\n",
    "\n",
    "\n",
    "foleder_name = ['rock/','paper/','scissor/']\n",
    "\n",
    "\n",
    "for i in foleder_name:\n",
    "    file_name = os.listdir(file_path+i)\n",
    "    start_num = 0 # 이어서 붙이고 싶은 번호를 적는다 \n",
    "    for j in file_name:\n",
    "        origin_name = file_path+i+j\n",
    "        change_name = file_path+i+str(start_num)+'.jpg'\n",
    "        os.rename(origin_name,change_name)\n",
    "        start_num +=1\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Train data  load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 489 입니다.\n",
      "x_train shape: (489, 28, 28, 3)\n",
      "y_train shape: (489,)\n"
     ]
    }
   ],
   "source": [
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=489   # 가위바위보 이미지 개수 총합에 주의하세요.  가위바위보를 합한 총합 개수\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/2ndWeek_0727_0731/rock_scissor_paper/dataset\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 이미지 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 네트워크 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 256)       7168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1638528   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 2,826,243\n",
      "Trainable params: 2,826,243\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# model을 직접 만들어 보세요.\n",
    "# Hint! model의 입력/출력부에 특히 유의해 주세요. 가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n",
    "# [[YOUR CODE]]\n",
    "\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(256, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(512, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 네트워크 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9\n",
      "16/16 [==============================] - 4s 223ms/step - loss: 80.9066 - accuracy: 0.4458\n",
      "Epoch 2/9\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.8017 - accuracy: 0.6544\n",
      "Epoch 3/9\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.5421 - accuracy: 0.7505\n",
      "Epoch 4/9\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.4096 - accuracy: 0.8262\n",
      "Epoch 5/9\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.3084 - accuracy: 0.8937\n",
      "Epoch 6/9\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.2315 - accuracy: 0.9080\n",
      "Epoch 7/9\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.1974 - accuracy: 0.9243\n",
      "Epoch 8/9\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.1790 - accuracy: 0.9427\n",
      "Epoch 9/9\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.1514 - accuracy: 0.9427\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f42004c8ad0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.compile()과 model.fit()을 사용해 봅시다.\n",
    "# [[YOUR CODE]]\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train,y_train,epochs=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Test용 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_test)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "# x_test, y_test를 만드는 방법은 x_train, y_train을 만드는 방법과 아주 유사합니다.\n",
    "# [[YOUR CODE]]\n",
    "\n",
    "\n",
    "\n",
    "def test_load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=300   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_test)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/2ndWeek_0727_0731/rock_scissor_paper/dataset/test_data\"\n",
    "(x_test, y_test) = test_load_data(image_dir_path)\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### model test_accuracy 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 495ms/step - loss: 0.2677 - accuracy: 0.9300\n",
      "## evaluation loss and_metrics ##\n",
      "[0.2677028775215149, 0.9300000071525574]\n"
     ]
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.evaluate()을 사용해 봅시다.\n",
    "# [[YOUR CODE]]\n",
    "\n",
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=128)\n",
    "print('## evaluation loss and_metrics ##')\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 결과에 대한 내용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 초반 시도시 0.3 ~0.4 정도의 accuracy에서 못벗어남\n",
    "- 데이터 증대로 0.4~ 0.5로 증가\n",
    "- hyperparameter 조절로 최대 0.56까지 증가\n",
    "- 그 후 네트워크 추가 및 삭제 , hyperparameter조정, 데이터 증가에도 별 변화 없음\n",
    "- 테스트 데이터를 한 사람의 사진으로만 이루어져 있어 제대로 맞춰지지 않는 것 같아 전체 데이터셋 통합 후 -> shuffle ->  train/test 로 분할시켜 진행 (가능여부 코치진에게 미리 확인함 ) \n",
    "- 이후 0.9대의 정확성 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
